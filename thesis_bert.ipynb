{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thesis_bert_final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWaPThCGJqeh",
        "colab_type": "text"
      },
      "source": [
        "Code based in part on examples from transformers library (https://github.com/huggingface/transformers/) and the tutorial by Chris McCormick and Nick Ryan (https://mccormickml.com/2019/07/22/BERT-fine-tuning/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfAPlwyKAghd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers==2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeSSucu4AxY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, Sampler, RandomSampler, SequentialSampler\n",
        "from tqdm import trange\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from transformers import BertForSequenceClassification, BertTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZCQFO4GAybL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BERT weights, tokenizer, and model to be used\n",
        "BERT_WEIGHTS = 'bert-base-multilingual-uncased'\n",
        "BERT_TOKENIZER = BertTokenizer\n",
        "BERT_MODEL = BertForSequenceClassification\n",
        "\n",
        "# Maximum sequence length is 53 based on max length in training set (34) times \n",
        "# 1.5 plus 2 for CLS and SEP tokens\n",
        "MAX_SEQ_LEN = 53\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5Tw3u30A0tQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_and_prepare_data(filename: str,\n",
        "                          delimiter: str = '\\t',\n",
        "                          header: str = None,\n",
        "                          names: list = ('sentence', 'intent'),\n",
        "                          test: bool = False,\n",
        "                          unique_labels: list = None):\n",
        "    \"\"\"\n",
        "    Loads in data from filename and prepares\n",
        "\n",
        "    :param test:\n",
        "    :param unique_labels:\n",
        "    :param filename: path to data file\n",
        "    :param delimiter: delimiter character for CSV (default: '\\t')\n",
        "    :param header: (default: None)\n",
        "    :param names: data column names if header is None (default: ['sentence', 'intent'])\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # Make sure training set labels provided if loading test data\n",
        "    if test:\n",
        "        assert(unique_labels)\n",
        "\n",
        "    names = list(names)\n",
        "\n",
        "    df = pd.read_csv(filename,\n",
        "                     delimiter=delimiter,\n",
        "                     header=header,\n",
        "                     names=names).dropna(how='any')\n",
        "\n",
        "    # Make sure test set labels were present in training set\n",
        "    if test or unique_labels:\n",
        "        df = df[df.intent.isin(unique_labels)]\n",
        "\n",
        "    print(f'Dataframe shape: {df.shape}')\n",
        "    df.sample(10)\n",
        "\n",
        "    sentences = df.sentence.values\n",
        "\n",
        "    # Get all unique labels, assign an integer value to each\n",
        "    if not test and not unique_labels:\n",
        "        unique_labels = sorted(list(set(df.intent.values)))\n",
        "    labels = [unique_labels.index(label) for label in df.intent.values]\n",
        "    print(f'Unique labels: {unique_labels}')\n",
        "\n",
        "    # Tokenize sentences based on weights from BERT_MODEL, adding CLS and SEP tokens\n",
        "    tokenizer = BERT_TOKENIZER.from_pretrained(BERT_WEIGHTS, add_special_tokens=True)\n",
        "    tokenized_sentences = [tokenizer.tokenize(sentence) for sentence in sentences]\n",
        "\n",
        "    # Use the BERT tokenizer to convert the tokens to their index numbers in the BERT vocabulary\n",
        "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_sentences]\n",
        "\n",
        "    # Pad/truncate ends of input sequences to MAX_LEN\n",
        "    input_ids = pad_sequences(input_ids, maxlen=MAX_SEQ_LEN, dtype='long',\n",
        "                              padding=\"post\", truncating=\"post\")\n",
        "\n",
        "    # TODO: find better way to do attention masks... what if embedding is (unrealistically) 0.0?\n",
        "    attention_masks = [[1 if i else 0 for i in seq] for seq in input_ids]\n",
        "\n",
        "    print(sentences[1])\n",
        "    print(tokenized_sentences[1])\n",
        "    print(attention_masks[1])\n",
        "    len(attention_masks[1])\n",
        "\n",
        "    if test:\n",
        "        return map(torch.tensor, (input_ids, attention_masks, labels))\n",
        "\n",
        "    # Split data and masks for training and validation\n",
        "    x_train, x_validate, y_train, y_validate = train_test_split(input_ids, labels,\n",
        "                                                                random_state=2018, test_size=0.1)\n",
        "    train_masks, validation_masks, _, _ = train_test_split(attention_masks, input_ids,\n",
        "                                                           random_state=2018, test_size=0.1)\n",
        "\n",
        "    # Convert all of our data into torch tensors, the required datatype for our model\n",
        "    data = (x_train, x_validate, y_train, y_validate, train_masks, validation_masks)\n",
        "\n",
        "    return map(torch.tensor, data), unique_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9BGGOGOA26h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_dataloader_from_tensors(x: torch.tensor,\n",
        "                                 y: torch.tensor,\n",
        "                                 masks: torch.tensor,\n",
        "                                 test: bool = False,\n",
        "                                 batch_size: int = 32):\n",
        "    \"\"\"\n",
        "    Constructs a DataLoader based on X, y, and masks\n",
        "\n",
        "    :param x:\n",
        "    :param y:\n",
        "    :param test:\n",
        "    :param masks:\n",
        "    :param batch_size: (Default: 32\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    sampler = SequentialSampler if test else RandomSampler\n",
        "\n",
        "    # Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n",
        "    # with an iterator the entire dataset does not need to be loaded into memory\n",
        "    tensor_dataset = TensorDataset(x, masks, y)\n",
        "    dataset_sampler = sampler(tensor_dataset)\n",
        "\n",
        "    return DataLoader(tensor_dataset, sampler=dataset_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylY8Ck8kA429",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_BERT_model(bert_model, bert_weights, num_labels):\n",
        "    # Load BERT model with pretrained weights and move to GPU if available\n",
        "    model = bert_model.from_pretrained(bert_weights, num_labels=num_labels)\n",
        "    if 'cuda' == device.type:\n",
        "        model.cuda()\n",
        "\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "    # no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "\n",
        "    # This variable contains all of the hyperparemeter information our training loop needs\n",
        "    optimizer = transformers.AdamW(optimizer_grouped_parameters, lr=2e-5)\n",
        "    scheduler = transformers.WarmupLinearSchedule(optimizer, warmup_steps=100, t_total=1000)\n",
        "\n",
        "    return model, optimizer, scheduler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjZ-c8E6A6Yd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score(y_true, y_pred, labels=None, scoring='f1-micro'):\n",
        "    \"\"\"\n",
        "    Calculates a score given a gold standard and a test set\n",
        "    :param y_true:\n",
        "    :param y_pred:\n",
        "    :param scoring: (default: 'f1-micro')\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    score_funcs = {'f1-micro': lambda x, y: f1_score(y_true=x, y_pred=y, labels=labels, average='micro'),\n",
        "                   'f1-macro': lambda x, y: f1_score(y_true=x, y_pred=y, labels=labels, average='macro'),\n",
        "                   'average': lambda x, y: (x == y).mean()}\n",
        "    assert(scoring in score_funcs)\n",
        "    return score_funcs[scoring](y_true, y_pred)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vGBSZ5yA71k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, optimizer, scheduler, data_loader_train, data_loader_validate, epochs=4, seed=500):\n",
        "    # Store our loss and accuracy for plotting\n",
        "    # train_loss_set = []\n",
        "\n",
        "    # Tracking variables\n",
        "    tr_loss = 0.0\n",
        "    tr_steps = 0\n",
        "\n",
        "    model.zero_grad()  # zero out gradients\n",
        "\n",
        "    train_iterator = trange(epochs, desc='Epoch')\n",
        "    # TODO: set_seed(seed)\n",
        "\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(data_loader_train, desc='Iteration')\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "            model.train()\n",
        "\n",
        "            # send batch to GPU (if available)\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            inputs = {'input_ids': batch[0],\n",
        "                      'attention_mask': batch[1],\n",
        "                      'labels': batch[2]}\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(**inputs)\n",
        "            loss = outputs[0]\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "            model.zero_grad()\n",
        "            tr_steps += 1\n",
        "\n",
        "        print(\"Train loss: {}\".format(tr_loss / tr_steps))\n",
        "\n",
        "        # Validation\n",
        "        validation_accuracy = evaluate(model, data_loader_validate)\n",
        "        print('Validation accuracy: {}'.format(validation_accuracy))\n",
        "\n",
        "    return tr_steps, tr_loss / tr_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evVuSYS9A-je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, data_loader_validate, scoring='average'):\n",
        "    eval_loss, eval_accuracy = 0.0, 0.0\n",
        "    eval_steps = 0\n",
        "\n",
        "    for batch in data_loader_validate:\n",
        "        model.eval()\n",
        "\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {'input_ids': batch[0],\n",
        "                      'attention_mask': batch[1],\n",
        "                      'labels': batch[2]}\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs[1]\n",
        "\n",
        "        preds = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].detach().cpu().numpy()\n",
        "\n",
        "        # TODO: should scoring be \"f1-micro\"?\n",
        "        preds = np.argmax(preds, axis=1)#.flatten()\n",
        "        tmp_eval_accuracy = score(y_true=label_ids, y_pred=preds, scoring=scoring)\n",
        "\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        eval_steps += 1\n",
        "\n",
        "    return eval_accuracy / eval_steps"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSc0jYnlBARb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: get rid of the \"true labels\" stuff from here...\n",
        "def predict(model, data_loader_predict):\n",
        "    model.eval()\n",
        "\n",
        "    predictions = list()\n",
        "    for batch in data_loader_predict:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs = {'input_ids': batch[0],\n",
        "                      'attention_mask': batch[1],\n",
        "                      'labels': batch[2]}\n",
        "            outputs = model(**inputs)\n",
        "            logits = outputs[1]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        preds = logits.detach().cpu().numpy()\n",
        "\n",
        "        # Store predictions and true labels\n",
        "        predictions.extend(preds)\n",
        "\n",
        "    return np.argmax(predictions, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A84fOnikBC_h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is where the magic starts..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdldqZS-BILa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Snips\n",
        "(x_train, x_validate, y_train, y_validate, train_masks, validation_mask), unique_labels = \\\n",
        "    load_and_prepare_data('./snips_train.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZNM4QoTFYkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Snips small\n",
        "(x_train, x_validate, y_train, y_validate, train_masks, validation_mask), unique_labels = \\\n",
        "    load_and_prepare_data('./snips_small_train.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNmQJOegxfL4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Almawave-SLU\n",
        "(x_train, x_validate, y_train, y_validate, train_masks, validation_mask), unique_labels = \\\n",
        "    load_and_prepare_data('./aw_slu_train.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UYoQtpcFcAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Almawave-SLU small\n",
        "(x_train, x_validate, y_train, y_validate, train_masks, validation_mask), unique_labels = \\\n",
        "    load_and_prepare_data('./aw_slu_small_train.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CaU94o0t6ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ATIS\n",
        "(x_train, x_validate, y_train, y_validate, train_masks, validation_mask), unique_labels = \\\n",
        "    load_and_prepare_data('./atis_train.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbdzUTUf_DFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ATIS small\n",
        "(x_train, x_validate, y_train, y_validate, train_masks, validation_mask), unique_labels = \\\n",
        "    load_and_prepare_data('./atis_small_train.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ-9rMoPBIjw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_loader_train = make_dataloader_from_tensors(x_train, y_train, train_masks)\n",
        "data_loader_validate = make_dataloader_from_tensors(x_validate, y_validate, validation_mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gmf121xJFrKG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = len(unique_labels)\n",
        "print(num_labels)\n",
        "print(unique_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcPX95KwFrlf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, optimizer, scheduler = build_BERT_model(bert_model=BERT_MODEL,\n",
        "                                               bert_weights=BERT_WEIGHTS,\n",
        "                                               num_labels=num_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zcIczRiFwoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(model, optimizer, scheduler, data_loader_train, data_loader_validate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAuU4C_GGENF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Snips test (\"dev\")\n",
        "prediction_ids, prediction_masks, prediction_labels = \\\n",
        "    load_and_prepare_data('snips_validate.tsv', test=True, unique_labels=unique_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJl40uX6vfRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Almawave-SLU test\n",
        "prediction_ids, prediction_masks, prediction_labels = \\\n",
        "    load_and_prepare_data('aw_slu_test.tsv', test=True, unique_labels=unique_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt_xhWF7xTzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ATIS test\n",
        "prediction_ids, prediction_masks, prediction_labels = \\\n",
        "    load_and_prepare_data('atis_dev.tsv', test=True, unique_labels=unique_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C22GJiqoQezc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_data_loader = make_dataloader_from_tensors(prediction_ids, prediction_labels,\n",
        "                                                      prediction_masks, test=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSyvzH2fQg9S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = predict(model, prediction_data_loader)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfxb9gmceJpG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true = np.array(prediction_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz_ohwt9a7EI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score(true, preds, scoring='average')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9482-yUfbB9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score(true, preds, scoring='f1-micro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99ActyP9noQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "score(true, preds, labels=np.unique(preds), scoring='f1-macro')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfPxI5racW8o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = true\n",
        "y_pred = preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNifOp2oeoF5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "conf = confusion_matrix(y_true, y_pred, labels=[x for x in range(len(unique_labels))])\n",
        "df_cm = pd.DataFrame(conf, index=unique_labels, columns=unique_labels)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HdEnpX13e7Qj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Snips and Almawave-SLU\n",
        "sn.heatmap(df_cm, annot=True, fmt='g', cmap=plt.cm.Blues).set_ylim(7.0, 0.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65uxoykvxj-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ATIS\n",
        "sn.heatmap(df_cm, annot=True, fmt='g', cmap=plt.cm.Blues).set_ylim(17.0, 0.0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dNT4N_q-xulm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ATIS\n",
        "plt.clf()\n",
        "plt.subplots(figsize=(20,15))\n",
        "# font = {'weight' : 'normal',\n",
        "#         'size'   : 22}\n",
        "# plt.rc('font', **font)\n",
        "chart = sn.heatmap(df_cm, annot=True, fmt='g', cmap=plt.cm.Blues)\n",
        "# chart.set_xticklabels(chart.get_xticklabels(), rotation=45)\n",
        "chart.set_ylim(17.0, 0.0)\n",
        "chart\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aa5P9m9M9U__",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chart.figure.savefig('atis_small_bert_cm.svg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBjLVYI_-36q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "Counter(y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQEMnYzHBU1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iToRMcrWBYRh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(y_pred, open('atis_full_bert_pred.pkl', 'wb'))\n",
        "pickle.dump(y_true, open('atis_full_bert_true.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5WlBrLqBooG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(y_pred, open('atis_small_bert_pred.pkl', 'wb'))\n",
        "pickle.dump(y_true, open('atis_small_bert_true.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yoAbxQQCTqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(unique_labels, open('atis_unique_labels.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaq3DcYyDYkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(y_pred, open('snips_full_bert_pred.pkl', 'wb'))\n",
        "pickle.dump(y_true, open('snips_full_bert_true.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzMuLhjhGMoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(y_pred, open('snips_small_bert_pred.pkl', 'wb'))\n",
        "pickle.dump(y_true, open('snips_small_bert_true.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGAmwXKZEeyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(unique_labels, open('snips_unique_labels.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13Fu65EFxW_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(y_pred, open('snips_train_4_epochs_aslu_test_bert_pred.pkl', 'wb'))\n",
        "pickle.dump(y_true, open('snips_train_4_epochs_aslu_test_bert_true.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHOQoFWuFXbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(y_pred, open('snips_train_8_epochs_aslu_test_bert_pred.pkl', 'wb'))\n",
        "pickle.dump(y_true, open('snips_train_8_epochs_aslu_test_bert_true.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s4AofdHG3BI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(y_pred, open('aslu_full_bert_pred.pkl', 'wb'))\n",
        "pickle.dump(y_true, open('aslu_full_bert_true.pkl', 'wb'))\n",
        "pickle.dump(unique_labels, open('aslu_unique_labels.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P-Lom2fHHRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(y_pred, open('aslu_small_bert_pred.pkl', 'wb'))\n",
        "pickle.dump(y_true, open('aslu_small_bert_true.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dE5e2HL_HRZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(y_pred, open('aslu_train_4_epochs_snips_test_bert_pred.pkl', 'wb'))\n",
        "pickle.dump(y_true, open('aslu_train_4_epochs_snips_test_bert_true.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOlwhm6eIN-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(y_pred, open('aslu_train_8_epochs_snips_test_bert_pred.pkl', 'wb'))\n",
        "pickle.dump(y_true, open('aslu_train_8_epochs_snips_test_bert_true.pkl', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}